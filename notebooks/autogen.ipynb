{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task Solving with Code Generation, Execution and Debugging\n",
    "In this notebook, we demonstrate how to use AssistantAgent and UserProxyAgent to write code and execute the code. Here AssistantAgent is an LLM-based agent that can write Python code (in a Python coding block) for a user to execute for a given task. UserProxyAgent is an agent which serves as a proxy for the human user to execute the code written by AssistantAgent, or automatically execute the code. Depending on the setting of human_input_mode and max_consecutive_auto_reply, the UserProxyAgent either solicits feedback from the human user or returns auto-feedback based on the result of code execution (success or failure and corresponding outputs) to AssistantAgent. AssistantAgent will debug the code and suggest new code if the result contains error. The two agents keep communicating to each other until the task is done.\n",
    "\n",
    "{=mdx}\n",
    ":::info Requirements\n",
    "Install the following packages before running the code below:\n",
    "```bash\n",
    "pip install autogen-agentchat~=0.2 matplotlib yfinance\n",
    "```\n",
    "\n",
    "For more information, please refer to the [installation guide](/docs/installation/).\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "flaml.automl is not available. Please install flaml[automl] to enable AutoML functionalities.\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'OAI_CONFIG_LIST'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mautogen\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mautogen\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcoding\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LocalCommandLineCodeExecutor\n\u001b[0;32m----> 6\u001b[0m config_list \u001b[38;5;241m=\u001b[39m \u001b[43mautogen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig_list_from_json\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mOAI_CONFIG_LIST\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilter_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtags\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgpt-4o\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# comment out to get all\u001b[39;49;00m\n\u001b[1;32m      9\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# When using a single openai endpoint, you can use the following:\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# config_list = [{\"model\": \"gpt-4o\", \"api_key\": os.getenv(\"OPENAI_API_KEY\")}]\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/python/3.12.1/lib/python3.12/site-packages/autogen/oai/openai_utils.py:519\u001b[0m, in \u001b[0;36mconfig_list_from_json\u001b[0;34m(env_or_file, file_location, filter_dict)\u001b[0m\n\u001b[1;32m    516\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    517\u001b[0m         config_list_path \u001b[38;5;241m=\u001b[39m env_or_file\n\u001b[0;32m--> 519\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mconfig_list_path\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m json_file:\n\u001b[1;32m    520\u001b[0m         config_list \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(json_file)\n\u001b[1;32m    521\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m filter_config(config_list, filter_dict)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'OAI_CONFIG_LIST'"
     ]
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "import autogen\n",
    "from autogen.coding import LocalCommandLineCodeExecutor\n",
    "\n",
    "config_list = [{\"model\": \"gpt-4o\", \"api_key\": os.getenv(\"OPENAI_API_KEY\")}]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
